# Техническая документация

## Как работает транскрибация

### Архитектура

1. **Web Audio API** - декодирование и обработка аудио
   - Создается AudioContext с частотой дискретизации 16kHz (оптимально для речи)
   - Аудиофайл загружается и декодируется в AudioBuffer
   - Создается BufferSource для воспроизведения

2. **Виртуальный аудио поток**
   - Используется MediaStreamDestination для создания виртуального микрофона
   - Аудио из файла перенаправляется в этот поток
   - Web Speech API слушает этот поток вместо реального микрофона

3. **Ускорение обработки**
   - playbackRate = 2.0 (воспроизведение в 2 раза быстрее)
   - gainNode с gain = 5.0 для усиления тихих записей
   - Реальное время обработки = длительность_аудио / 2

4. **Web Speech API**
   - Распознает речь из виртуального потока
   - Работает в режиме continuous для обработки всего файла
   - Автоматически перезапускается при ошибках no-speech/aborted

5. **Диаризация**
   - K-means кластеризация на основе акустических характеристик
   - Анализ: энергия, высота тона (pitch), Zero-Crossing Rate
   - Автоматическое определение 2 говорящих
   - Сглаживание переходов между говорящими

### Обработка ошибок

#### "no-speech"
- Возникает когда API не распознает речь в текущем фрагменте
- Приложение автоматически перезапускает распознавание
- Счетчик noSpeechCount ограничен 20 попытками
- После 20 попыток завершается обработка

#### "aborted"
- Возникает при принудительной остановке
- Автоматически перезапускается если shouldContinue = true
- Задержка перед перезапуском 200ms

#### "not-allowed"
- Пользователь запретил доступ к микрофону
- Обработка прерывается с понятным сообщением

### Оптимизации

1. **Частота дискретизации 16kHz**
   - Достаточно для речи (человеческий голос 80Hz - 3kHz)
   - Снижает нагрузку на процессор
   - Ускоряет обработку

2. **Усиление сигнала (Gain = 5.0)**
   - Помогает распознавать тихие записи
   - Улучшает работу с плохим качеством

3. **Прогрессивная обработка**
   - Прогресс обновляется каждые 500ms
   - Сегменты отображаются в реальном времени
   - Не блокирует UI

4. **Обработка пустых результатов**
   - Если segments.length === 0, создается заглушка
   - Пользователь всегда получает результат
   - Статус записи меняется на "completed"

### Ограничения

1. **Зависимость от Google**
   - Web Speech API работает через облако Google
   - Требуется интернет
   - Качество зависит от сервера Google

2. **Браузерная поддержка**
   - Chrome/Edge: отличная поддержка
   - Firefox: ограниченная
   - Safari: не рекомендуется

3. **Качество распознавания**
   - Зависит от качества аудио
   - Фоновый шум снижает точность
   - Акцент может влиять на результат

4. **Диаризация**
   - Работает для 2 говорящих
   - Не идеальна для перекрывающихся голосов
   - Может путать говорящих с похожими голосами

## Потенциальные улучшения

### Краткосрочные
1. Добавить выбор языка
2. Настраиваемая скорость обработки (1.5x, 2x, 3x)
3. Пауза/возобновление обработки
4. Предпросмотр первых 10 секунд

### Долгосрочные
1. Использовать Whisper API для лучшего качества
2. Серверная обработка для больших файлов
3. Обучение speaker recognition на образцах голосов
4. Поддержка >2 говорящих
5. Редактирование транскрипции после обработки
6. Автоматическая пунктуация
7. Распознавание эмоций

## Производительность

- 1-минутное аудио: ~30 секунд обработки
- 5-минутное аудио: ~2.5 минуты обработки
- 10-минутное аудио: ~5 минут обработки
- Максимальная рекомендуемая длина: 30 минут

## Требования к файлам

- Формат: MP3, WAV, M4A, OGG
- Битрейт: минимум 64 kbps, рекомендуется 128 kbps
- Частота: 16kHz - 48kHz
- Каналы: моно или стерео (конвертируется в моно)
- Максимальный размер: ограничен браузером (~100-200 МБ)
